{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Social Networks - Assignment 4\n",
    "\n",
    "This **Home Assignment** is **mandatory**, it does count towards your final chance to take part in the exam. \n",
    "\n",
    "You can expect numpy, torch, torch_geometric, matplotlib, and networkx to be installed.\n",
    "\n",
    "## Formalities\n",
    "\n",
    "**Submit in a group of 3-4 people until 10.07.2022 23:59CET. The deadline is strict!**\n",
    "\n",
    "You have the opportunity for an prelim submission until 07.07.2022 23:59 CET. We will run your code once, and you can thus see whether there are small bugs that you might not have expected.\n",
    "\n",
    "## Evaluation and Grading\n",
    "General advice for programming excercises at *CSSH*:\n",
    "Evaluation of your submission is done semi-automatically. Think of it as this notebook being \n",
    "executed once. Afterwards, some test functions are appended to this file and executed respectively.\n",
    "\n",
    "Therefore:\n",
    "* Submit valid _Python3_ code only!\n",
    "* Use external libraries only when specified by task.\n",
    "* Ensure your definitions (functions, classes, methods, variables) follow the specification if\n",
    "  given. The concrete signature of e.g. a function usually can be inferred from task description, \n",
    "  code skeletons and test cases.\n",
    "* Ensure the notebook does not rely on current notebook or system state!\n",
    "  * Use `Kernel --> Restart & Run All` to see if you are using any definitions, variables etc. that \n",
    "    are not in scope anymore.\n",
    "* Keep your code idempotent! Running it or parts of it multiple times must not yield different\n",
    "  results. Minimize usage of global variables.\n",
    "* Ensure your code / notebook terminates in reasonable time.\n",
    "\n",
    "**There's a story behind each of these points! Don't expect us to fix your stuff!**\n",
    "\n",
    "Regarding the scores, you will get no points for a task if:\n",
    "- your function throws an unexpected error (e.g. takes the wrong number of arguments)\n",
    "- gets stuck in an infinite loop\n",
    "- takes much much longer than expected (e.g. >1s to compute the mean of two numbers)\n",
    "- does not produce the desired output (e.g. returns an descendingly sorted list even though we asked for ascending, returns the mean and the std even though we asked for only the mean, prints an output instead of returning it!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# credentials of all team members (you may add or remove members from the list)\n",
    "team_members = [\n",
    "    {\n",
    "        'first_name': 'Some',\n",
    "        'last_name': 'One',\n",
    "        'student_id': 123451\n",
    "    },\n",
    "    {\n",
    "        'first_name': 'Bob',\n",
    "        'last_name': 'Bar',\n",
    "        'student_id': 54321\n",
    "    },\n",
    "    {\n",
    "        'first_name': 'Not',\n",
    "        'last_name': 'Sure',\n",
    "        'student_id': 15432\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /opt/anaconda3/lib/python3.9/site-packages (1.11.0)\n",
      "Requirement already satisfied: typing-extensions in /opt/anaconda3/lib/python3.9/site-packages (from torch) (4.1.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/Users/mcpunjabi/Documents/Social Network/social-networks-assignments/HA4_tasks.ipynb Cell 4'\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mcpunjabi/Documents/Social%20Network/social-networks-assignments/HA4_tasks.ipynb#ch0000002?line=0'>1</a>\u001b[0m \u001b[39m# As usual all provided output was obtained with the following torch version\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mcpunjabi/Documents/Social%20Network/social-networks-assignments/HA4_tasks.ipynb#ch0000002?line=1'>2</a>\u001b[0m \u001b[39m#  different outputs could be possible with different package version\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/mcpunjabi/Documents/Social%20Network/social-networks-assignments/HA4_tasks.ipynb#ch0000002?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mcpunjabi/Documents/Social%20Network/social-networks-assignments/HA4_tasks.ipynb#ch0000002?line=3'>4</a>\u001b[0m \u001b[39mprint\u001b[39m(torch\u001b[39m.\u001b[39m__version__) \u001b[39m#1.10.1\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mcpunjabi/Documents/Social%20Network/social-networks-assignments/HA4_tasks.ipynb#ch0000002?line=4'>5</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch_geometric\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "# As usual all provided output was obtained with the following torch version\n",
    "#  different outputs could be possible with different package version\n",
    "import torch\n",
    "print(torch.__version__) #1.10.1\n",
    "import torch_geometric\n",
    "print(torch_geometric.__version__) # 2.0.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## You own GCN (5)\n",
    "\n",
    "Create a GCN layer as introduced in the lecture (compare deck 09 slide 62, without the activation function) using PyTorch Geometric. Therefore, use the `MyGCN` class provided below and add code to the `forward` and `message` functions. \n",
    "\n",
    "While in the lecture the normalization constant $c_i$ is $|N(i)|$, for this task we are using a normalization function of $c_i = \\sqrt{|N_{\\text{in}}(i)| |N_{\\text{out}}(i)|}$ which for undirected networks comes out to be equal to the lecture definition.\n",
    "\n",
    "Notice that datasets that we encounter later on are (potentially) directed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import Linear, Parameter\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.utils import degree\n",
    "\n",
    "class MyGCN(MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__(aggr='add')\n",
    "        \n",
    "        \n",
    "        self.W0 = Linear(in_channels, out_channels, bias=False)\n",
    "        self.W1 = Linear(in_channels, out_channels, bias=False)\n",
    "        self.b = Parameter(torch.Tensor(out_channels))\n",
    "\n",
    "        self.reset_parameters()\n",
    "        \n",
    "    def reset_parameters(self):\n",
    "        self.W0.reset_parameters()\n",
    "        self.W1.reset_parameters()\n",
    "        self.b.data.zero_()\n",
    "        \n",
    "    def forward(self, x, edge_index):\n",
    "        pass\n",
    "    \n",
    "        \"\"\"Implement most of the work here\n",
    "        Notice that pytorch geometric MessagePassing class inherits self.propagate\n",
    "          which essentially already has most of the message passing implemented already\n",
    "        \"\"\"\n",
    "    \n",
    "    def message(self, x_j, norm):\n",
    "        \"\"\"Implement normalisation here\"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create example Graph (deck 09 slide 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = \"\"\"0 1\n",
    "0 2\n",
    "0 3\n",
    "1 0\n",
    "1 2\n",
    "1 3\n",
    "2 0\n",
    "2 1\n",
    "2 4\n",
    "3 0\n",
    "3 1\n",
    "3 4\n",
    "4 2\n",
    "4 3\n",
    "4 5\n",
    "5 4\n",
    "5 6\n",
    "5 7\n",
    "6 5\n",
    "6 8\n",
    "6 9\n",
    "7 5\n",
    "7 8\n",
    "7 9\n",
    "8 6\n",
    "6 7\n",
    "8 9\n",
    "9 7\n",
    "9 6\n",
    "9 8\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = []\n",
    "for line in s.splitlines():\n",
    "    a, b = line.split(\" \")\n",
    "    edges.append((int(a),int(b)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.Graph(edges)\n",
    "my_pos = nx.spring_layout(G, seed = 4)\n",
    "nx.draw(G, pos=my_pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reproduce the lecture results (2)\n",
    "\n",
    "In the lecture, you have seen one special case of a GCN (on deck 09 slides 64 you find the definition). To reproduce the results of this case here, we need two functions `create_initial_embeddings` (returning the initial embeddings as specified on the lecture slide and `set_weights` (adjusting the weights of the GCN to be equal to those of the lecture slide, no output). Implement both functions below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_initial_embeddings():\n",
    "    \"\"\"Your code here\"\"\"\n",
    "    return torch.tensor([(0,1)],dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_embed = create_initial_embeddings()\n",
    "initial_embed.shape #torch.Size([10, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_weights(layer):\n",
    "    with torch.no_grad():\n",
    "        \"\"\"Your code here\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "layer = MyGCN(2,2)\n",
    "set_weights(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer.W0.weight\n",
    "\n",
    "#Parameter containing:\n",
    "#tensor([[1., 0.],\n",
    "#        [0., 0.]], requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer.W1.weight\n",
    "\n",
    "#Parameter containing:\n",
    "#tensor([[0., 0.],\n",
    "#        [1., 0.]], requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer.b\n",
    "\n",
    "#Parameter containing:\n",
    "#tensor([0., 0.], requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index = torch.tensor(edges, dtype=torch.long).T\n",
    "edge_index\n",
    "\n",
    "#tensor([[0, 0, 0, 1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4, 5, 5, 5, 6, 6, 6, 7, 7, 7,\n",
    "#         8, 6, 8, 9, 9, 9],\n",
    "#        [1, 2, 3, 0, 2, 3, 0, 1, 4, 0, 1, 4, 2, 3, 5, 4, 6, 7, 5, 8, 9, 5, 8, 9,\n",
    "#         6, 7, 9, 7, 6, 8]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer(initial_embed, edge_index)\n",
    "#tensor([[0.0000, 0.0000],\n",
    "#        [0.0000, 0.0000],\n",
    "#        [0.0000, 0.3333],\n",
    "#        [0.0000, 0.3333],\n",
    "#        [1.0000, 0.3333],\n",
    "#        [1.0000, 0.3333],\n",
    "#        [0.0000, 0.3333],\n",
    "#        [0.0000, 0.3333],\n",
    "#        [0.0000, 0.0000],\n",
    "#        [0.0000, 0.0000]], grad_fn=<AddBackward0>)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi Layer GCN (3)\n",
    "\n",
    "We will now use our defined Convolution Layer to create a GCN with variable number of \"hidden layers\" using the `MultiLayerGCN` class below.\n",
    "\n",
    "The network always starts with an initial layer mapping node features onto the size of the hidden dim. No activation function is used after this layer. This layer is of shape `node_features_dim` x `hidden_dim`.\n",
    "Then, we apply `num_hidden_layers` hidden layers of shape `hidden_dim` x `hidden_dim`, each followed by a `ReLu` activation function.\n",
    "The network terminates with an output layer of shape `hidden_dim ` x `num_classes`  that is followed by a `log_sofmax` activation.\n",
    "\n",
    "All layers are of type `MyGCN`. For reproducability reasons, layers are initialized in the same order they are traversed in a forward pass. You find a usage example below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import Planetoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiLayerGCN(torch.nn.Module):\n",
    "    def __init__(self, node_features_dim, hidden_dim, num_classes, num_hidden_layers=0):\n",
    "        super().__init__()\n",
    "        self.layers = []\n",
    "        \"\"\"Your code to fill up the layers here\"\"\"\n",
    "        \n",
    "        self.layers = torch.nn.ModuleList(self.layers)\n",
    "\n",
    "    def forward(self, data):\n",
    "        \"\"\"Your code for the forward pass here\"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example training loop\n",
    "def training(model, data, n_epochs = 200):\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(n_epochs):\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "        loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking initialization with fixed seed\n",
    "torch.manual_seed(1)\n",
    "tmp_GCN = MultiLayerGCN(3, 2, 2, 0)\n",
    "print(tmp_GCN.layers[0].W0.weight)\n",
    "#tensor([[ 0.2109, -0.2250, -0.0421],\n",
    "#        [-0.0520,  0.0837, -0.0023]], requires_grad=True)\n",
    "tmp_GCN.layers[1].W0.weight\n",
    "#tensor([[ 0.4667, -0.6443],\n",
    "#        [-0.6723, -0.3411]], requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking initialization with fixed seed\n",
    "torch.manual_seed(1)\n",
    "tmp_GCN = MultiLayerGCN(3, 2, 2, 1)\n",
    "for i in range(3):\n",
    "    print(tmp_GCN.layers[i].W0.weight)\n",
    "    \n",
    "# Parameter containing:\n",
    "#tensor([[ 0.2109, -0.2250, -0.0421],\n",
    "#        [-0.0520,  0.0837, -0.0023]], requires_grad=True)\n",
    "#Parameter containing:\n",
    "#tensor([[ 0.4667, -0.6443],\n",
    "#        [-0.6723, -0.3411]], requires_grad=True)\n",
    "#Parameter containing:\n",
    "#tensor([[-0.2042, -0.0775],\n",
    "#        [-0.6798, -0.3371]], requires_grad=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import the Cora dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Planetoid(root='/tmp/Cora', name='Cora', split=\"public\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = MultiLayerGCN(dataset.num_node_features, 16, dataset.num_classes, 0).to(device)\n",
    "\n",
    "\n",
    "data = dataset[0].to(device)\n",
    "\n",
    "training(model, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate the model on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_accuracy(model, data):\n",
    "    model.eval()\n",
    "    pred = model(data).argmax(dim=1)\n",
    "    correct = (pred[data.test_mask] == data.y[data.test_mask]).sum()\n",
    "    acc = int(correct) / int(data.test_mask.sum())\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = get_test_accuracy(model, data)\n",
    "print(f'# Accuracy: {acc:.8f}')\n",
    "# Accuracy: 0.77000000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Are more layers always better? (3)\n",
    "\n",
    "You will now look into finding the optimal number of layers that you should use in your Multi-Layer GCN. Therefore, evaluate different configurations on different datasets. For the three datasets `(\"Cora\", \"CiteSeer\", \"PubMed\")` compute the accuracy of a fitted `MultiLayerGCN` with `hidden_dim` of 16 and a varying number (`[0, 1, 2, 3, 4]`) of hidden layers.\n",
    "\n",
    "Repeat the experiment 10 times for each of the settings using a different seed ([0..9]) each time.\n",
    "\n",
    "Collect the result of the experiments in a dictionary `results` that maps the names of the datasets to list of list. e.g. `results[\"Cora\"][1][2]` holds the results for the Cora dataset with 1 \"hidden layer\" and an initial seed of 2.\n",
    "\n",
    "Use the `\"public\"` splits of the datasets. Plot the mean and standard deviation of the accuracy as a function of hidden layers in an errorbar plot. Save the a plot containing lines for all three datasets as `accuracies.png` here in the notebook.\n",
    "\n",
    "### What do we observe? (2)\n",
    "\n",
    "Describe what you see in your own words. Then interpret your findings. Save your text in the `your_observation` variable provided below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import Planetoid\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# computations take about 5 min\n",
    "results = {\"Cora\" : [], \"CiteSeer\" : [], \"PubMed\" : []}\n",
    "for dataset_name in (\"Cora\", \"CiteSeer\", \"PubMed\"):\n",
    "    for n_hidden in range(5):\n",
    "        for seed in range(10):\n",
    "            torch.manual_seed(seed) # !set seed before initializing the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results\n",
    "#{'Cora': \n",
    "# [[0.767,   0.77,   0.778,   0.777,   0.764,   0.777,   0.773,   0.762,   0.763,   0.774],\n",
    "#  [0.792, 0.785, 0.777, 0.776, 0.78, 0.776, 0.769, 0.789, 0.799, 0.778],\n",
    "#  [0.747, 0.76, 0.745, 0.769, 0.747, 0.736, 0.776, 0.781, 0.761, 0.766],\n",
    "#  [0.727, 0.737, 0.729, 0.688, 0.729, 0.744, 0.727, 0.717, 0.593, 0.709],\n",
    "#  [0.687, 0.598, 0.674, 0.702, 0.716, 0.746, 0.679, 0.651, 0.719, 0.738]],\n",
    "# 'CiteSeer': \n",
    "# [[0.694,   0.688,   0.686,   0.69,   0.681,   0.688,   0.679,   0.679,   0.685,   0.687],\n",
    "#  [0.674, 0.68, 0.679, 0.643, 0.675, 0.687, 0.665, 0.67, 0.638, 0.663],\n",
    "#  [0.59, 0.576, 0.641, 0.624, 0.598, 0.568, 0.637, 0.61, 0.655, 0.55],\n",
    "#  [0.627, 0.519, 0.625, 0.608, 0.627, 0.631, 0.55, 0.612, 0.5, 0.563],\n",
    "#  [0.607, 0.524, 0.521, 0.476, 0.491, 0.576, 0.47, 0.509, 0.543, 0.578]],\n",
    "# 'PubMed':\n",
    "# [[0.77,   0.769,   0.759,   0.767,   0.77,   0.769,   0.764,   0.769,   0.766,   0.768],\n",
    "#  [0.79, 0.774, 0.779, 0.786, 0.788, 0.788, 0.784, 0.786, 0.788, 0.787],\n",
    "#  [0.763, 0.792, 0.793, 0.782, 0.786, 0.751, 0.623, 0.797, 0.772, 0.783],\n",
    "#  [0.786, 0.734, 0.723, 0.764, 0.779, 0.778, 0.714, 0.704, 0.735, 0.756],\n",
    "#  [0.668, 0.667, 0.767, 0.759, 0.67, 0.725, 0.707, 0.724, 0.771, 0.728]]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "your_observation = \"Here goes your text\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
